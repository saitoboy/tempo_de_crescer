#!/usr/bin/env python3
"""
üè∑Ô∏è THEMATIC_CLASSIFIER.PY v3.1 - Classificador H√≠brido (TF-IDF + Heur√≠stico)

METODOLOGIA:
Este √© um sistema h√≠brido que combina:
1. TF-IDF estat√≠stico para tokens individuais
2. Scoring heur√≠stico para n-grams teol√≥gicos (frases-chave)
3. Contextualiza√ß√£o sem√¢ntica para desambigua√ß√£o

DECIS√ÉO METODOL√ìGICA:
Escolhemos modelo h√≠brido porque:
- Teologia usa frases t√©cnicas ("novo nascimento", "justifica√ß√£o pela f√©")
- TF-IDF puro n√£o captura sem√¢ntica teol√≥gica
- Heur√≠stica pura n√£o generaliza
- H√≠brido maximiza interpretabilidade + acur√°cia contextual

CIENTISTA RESPONS√ÅVEL: Guilherme Saito
VERS√ÉO: 3.1 (Rigorosa)
DATA: Janeiro 2026
"""

import json
import re
import math
from typing import Dict, List, Optional, Tuple, Set
from collections import Counter, defaultdict
from pathlib import Path
import statistics


class ThematicClassifier:
    """
    Classificador Tem√°tico H√≠brido (TF-IDF + Heur√≠stico)
    
    Combina an√°lise estat√≠stica (TF-IDF) com conhecimento teol√≥gico especialista
    para classificar prega√ß√µes na Taxonomia de Wayne Grudem.
    """
    
    def __init__(self):
        """Inicializa o classificador"""
        
        # ========== TAXONOMIA DE GRUDEM ==========
        self.taxonomia_grudem = {
            1: {
                "nome": "Doutrina da Palavra de Deus",
                "pergunta_central": "O que esta prega√ß√£o ensina sobre a B√≠blia e sua autoridade?",
                "subtemas": [
                    "Autoridade das Escrituras",
                    "Sufici√™ncia da Palavra",
                    "Revela√ß√£o de Deus",
                    "Prega√ß√£o expositiva",
                    "Aplica√ß√£o da Palavra"
                ]
            },
            2: {
                "nome": "Doutrina de Deus",
                "pergunta_central": "Quem Deus √©, segundo esta mensagem?",
                "subtemas": [
                    "Car√°ter de Deus",
                    "Santidade de Deus",
                    "Soberania de Deus",
                    "Trindade",
                    "Deus como Criador e Sustentador"
                ]
            },
            3: {
                "nome": "Doutrina do Homem",
                "pergunta_central": "O que esta prega√ß√£o ensina sobre a condi√ß√£o humana?",
                "subtemas": [
                    "Pecado",
                    "Queda",
                    "Consci√™ncia",
                    "Idolatria do cora√ß√£o",
                    "Necessidade de salva√ß√£o"
                ]
            },
            4: {
                "nome": "Doutrina de Cristo",
                "pergunta_central": "Quem √© Jesus e qual √© o Seu papel?",
                "subtemas": [
                    "Encarna√ß√£o",
                    "Cruz",
                    "Ressurrei√ß√£o",
                    "Senhorio de Cristo",
                    "Media√ß√£o"
                ]
            },
            5: {
                "nome": "Doutrina da Salva√ß√£o",
                "pergunta_central": "Como o ser humano √© salvo?",
                "subtemas": [
                    "Novo nascimento",
                    "Justifica√ß√£o",
                    "Gra√ßa",
                    "F√©",
                    "Santifica√ß√£o",
                    "Perseveran√ßa dos santos"
                ]
            },
            6: {
                "nome": "Doutrina do Esp√≠rito Santo",
                "pergunta_central": "Como o Esp√≠rito Santo atua na vida do crente?",
                "subtemas": [
                    "Regenera√ß√£o",
                    "Convic√ß√£o do pecado",
                    "Vida no Esp√≠rito",
                    "Santifica√ß√£o",
                    "Consola√ß√£o"
                ]
            },
            7: {
                "nome": "Doutrina da Igreja",
                "pergunta_central": "O que significa viver como corpo de Cristo?",
                "subtemas": [
                    "Corpo de Cristo",
                    "Comunh√£o",
                    "Disciplina",
                    "Perd√£o",
                    "Miss√£o",
                    "Vida comunit√°ria"
                ]
            },
            8: {
                "nome": "Doutrina das √öltimas Coisas",
                "pergunta_central": "Para onde caminha a hist√≥ria e a f√© crist√£?",
                "subtemas": [
                    "Esperan√ßa crist√£",
                    "Ju√≠zo final",
                    "Eternidade",
                    "Segunda vinda de Cristo",
                    "Nova cria√ß√£o"
                ]
            }
        }
        
        
        # ========== N-GRAMS TEOL√ìGICOS (SCORING HEUR√çSTICO) ==========
        # Frases completas que TF-IDF n√£o captura adequadamente
        self.ngrams_teologicos = {
            1: {
                "alta": [
                    "autoridade das escrituras",
                    "sufici√™ncia da palavra",
                    "inerr√¢ncia b√≠blica",
                    "prega√ß√£o expositiva",
                    "sola scriptura"
                ],
                "media": [
                    "palavra de deus",
                    "est√° escrito",
                    "assim diz o senhor"
                ]
            },
            2: {
                "alta": [
                    "santidade de deus",
                    "soberania de deus",
                    "gl√≥ria de deus",
                    "atributos de deus",
                    "natureza divina"
                ],
                "media": [
                    "santo dos santos",
                    "deus todo-poderoso"
                ]
            },
            3: {
                "alta": [
                    "natureza pecaminosa",
                    "deprava√ß√£o total",
                    "queda do homem",
                    "todos pecaram"
                ],
                "media": [
                    "cora√ß√£o do homem",
                    "inclina√ß√£o ao pecado"
                ]
            },
            4: {
                "alta": [
                    "cruz de cristo",
                    "sangue de cristo",
                    "cordeiro de deus",
                    "ressurrei√ß√£o de cristo",
                    "morte substitutiva",
                    "obra redentora"
                ],
                "media": [
                    "filho de deus",
                    "senhor jesus"
                ]
            },
            5: {
                "alta": [
                    "justifica√ß√£o pela f√©",
                    "novo nascimento",
                    "nascer de novo",
                    "somos salvos pela gra√ßa",
                    "arrependimento e f√©",
                    "gra√ßa salvadora",
                    "santifica√ß√£o progressiva",
                    "sola fide",
                    "sola gratia"
                ],
                "media": [
                    "vida eterna",
                    "perd√£o de pecados",
                    "reconcilia√ß√£o com deus"
                ]
            },
            6: {
                "alta": [
                    "esp√≠rito santo",
                    "batismo no esp√≠rito",
                    "cheios do esp√≠rito",
                    "fruto do esp√≠rito",
                    "dons espirituais",
                    "vida no esp√≠rito"
                ],
                "media": [
                    "consolador",
                    "poder do esp√≠rito"
                ]
            },
            7: {
                "alta": [
                    "corpo de cristo",
                    "noiva de cristo",
                    "comunh√£o dos santos",
                    "edificar a igreja",
                    "miss√£o da igreja"
                ],
                "media": [
                    "fam√≠lia de deus",
                    "povo de deus"
                ]
            },
            8: {
                "alta": [
                    "segunda vinda de cristo",
                    "volta de jesus",
                    "ju√≠zo final",
                    "ressurrei√ß√£o dos mortos",
                    "novos c√©us e nova terra",
                    "vida eterna",
                    "esperan√ßa gloriosa"
                ],
                "media": [
                    "maranata",
                    "dia do senhor"
                ]
            }
        }
        
        
        # ========== TOKENS SIMPLES (TF-IDF PURO) ==========
        self.tokens_simples = {
            1: ["b√≠blia", "escritura", "palavra", "revela√ß√£o"],
            2: ["deus", "senhor", "criador", "alt√≠ssimo"],
            3: ["pecado", "pecador", "carne", "transgress√£o"],
            4: ["jesus", "cristo", "salvador", "messias"],
            5: ["salva√ß√£o", "gra√ßa", "f√©", "reden√ß√£o"],
            6: ["esp√≠rito", "un√ß√£o", "consolador"],
            7: ["igreja", "irm√£os", "comunidade"],
            8: ["eternidade", "c√©u", "esperan√ßa", "glorifica√ß√£o"]
        }
        
        
        # ========== REGRAS DE DESAMBIGUA√á√ÉO CONTEXTUAL ==========
        self.regras_contexto = {
            "santifica√ß√£o": {
                # "santifica√ß√£o" pode ser Salva√ß√£o (5) ou Esp√≠rito Santo (6)
                "pneumatologia_triggers": ["esp√≠rito santo", "esp√≠rito opera", "pelo esp√≠rito"],
                "soteriologia_triggers": ["fruto da salva√ß√£o", "processo de", "progressiva"]
            },
            "gra√ßa": {
                # "gra√ßa" pode ser Deus (2) ou Salva√ß√£o (5)
                "deus_triggers": ["car√°ter de deus", "atributo", "natureza"],
                "salvacao_triggers": ["somos salvos", "justificados", "mediante a gra√ßa"]
            }
        }
        
        
        # ========== PESOS CALIBRADOS ==========
        self.pesos = {
            # Heur√≠stico (frases teol√≥gicas)
            "titulo_ngram_alta": 6.0,           # N-gram teol√≥gico no t√≠tulo
            "titulo_ngram_media": 4.0,
            "conteudo_ngram_alta": 3.0,         # N-gram no conte√∫do
            "conteudo_ngram_media": 1.5,
            
            # TF-IDF (tokens simples)
            "titulo_token_tfidf": 4.0,          # Token com TF-IDF no t√≠tulo
            "conteudo_token_tfidf": 1.0,        # Token com TF-IDF no conte√∫do
            
            # B√¥nus
            "bonus_diversidade": 2.5,           # M√∫ltiplas express√µes espec√≠ficas
            "livro_biblico": 1.0,               # Peso reduzido (desempate)
            "contexto_direcional": 2.0          # B√¥nus por contexto identificado
        }
        
        
        # ========== CACHE TF-IDF ==========
        self.idf_cache = {}
        self.total_documentos = 0
        self.pontuacoes_historico = defaultdict(list)  # Para calcular percentis
    
    
    def treinar_idf(self, pregacoes: List[Dict]):
        """
        Treina IDF (Inverse Document Frequency) APENAS para tokens simples
        
        DECIS√ÉO METODOL√ìGICA:
        N-grams teol√≥gicos usam scoring heur√≠stico, n√£o TF-IDF
        Apenas tokens individuais s√£o processados estatisticamente
        
        Args:
            pregacoes: Lista completa de prega√ß√µes
        """
        print("\nüß† Treinando TF-IDF (apenas tokens simples)...")
        
        self.total_documentos = len(pregacoes)
        documento_com_palavra = Counter()
        
        # Conta em quantos documentos cada TOKEN aparece
        for pregacao in pregacoes:
            conteudo = f"{pregacao.get('titulo', '')} {pregacao.get('conteudo_limpo', '')}".lower()
            
            # Tokeniza (palavras simples, n√£o frases)
            palavras_unicas = set(conteudo.split())
            
            for palavra in palavras_unicas:
                documento_com_palavra[palavra] += 1
        
        # Calcula IDF
        for palavra, doc_freq in documento_com_palavra.items():
            self.idf_cache[palavra] = math.log(self.total_documentos / doc_freq)
        
        print(f"‚úÖ IDF calculado para {len(self.idf_cache):,} tokens")
        
        # Mostra distribui√ß√£o
        palavras_raras = sorted(self.idf_cache.items(), key=lambda x: x[1], reverse=True)[:5]
        palavras_comuns = sorted(self.idf_cache.items(), key=lambda x: x[1])[:5]
        
        print(f"\n   üìä Tokens RAROS (IDF alto):")
        for palavra, idf in palavras_raras:
            print(f"      ‚Ä¢ {palavra}: {idf:.2f}")
        
        print(f"\n   üìä Tokens COMUNS (IDF baixo):")
        for palavra, idf in palavras_comuns:
            print(f"      ‚Ä¢ {palavra}: {idf:.2f}")
    
    
    def calcular_tfidf_token(self, token: str, freq: int) -> float:
        """
        Calcula TF-IDF de um TOKEN individual
        
        Args:
            token: Palavra simples
            freq: Frequ√™ncia no documento
            
        Returns:
            Score TF-IDF
        """
        idf = self.idf_cache.get(token.lower(), 1.0)
        return freq * idf
    
    
    def normalizar_por_tamanho(self, pontuacao: float, tamanho_doc: int) -> float:
        """
        Normaliza pontua√ß√£o pelo tamanho do documento
        
        JUSTIFICATIVA CIENT√çFICA:
        Documentos longos naturalmente t√™m mais matches
        Normaliza√ß√£o evita vi√©s de tamanho
        
        Args:
            pontuacao: Pontua√ß√£o bruta
            tamanho_doc: N√∫mero de palavras
            
        Returns:
            Pontua√ß√£o normalizada
        """
        # Normaliza para documento de 1000 palavras (baseline)
        baseline = 1000
        fator = baseline / max(tamanho_doc, 100)  # min 100 para evitar divis√£o extrema
        
        return pontuacao * fator
    
    
    def classificar_pregacao(self, pregacao: Dict) -> Dict:
        """
        Classifica prega√ß√£o usando modelo h√≠brido
        
        Args:
            pregacao: Prega√ß√£o enriquecida
            
        Returns:
            Prega√ß√£o classificada
        """
        titulo = pregacao.get('titulo', '')
        conteudo = pregacao.get('conteudo_limpo', '')
        meta = pregacao.get('metadados_biblicos', {})
        livro_principal = meta.get('livro_principal', '')
        
        titulo_lower = titulo.lower()
        conteudo_lower = conteudo.lower()
        tamanho_doc = len(conteudo.split())
        
        # Calcula pontua√ß√µes
        pontuacoes_brutas = defaultdict(float)
        
        # ========== PATH A: SCORING HEUR√çSTICO (N-GRAMS) ==========
        for cat_id, ngrams in self.ngrams_teologicos.items():
            expressoes_especificas = 0
            
            # Alta especificidade
            for ngram in ngrams.get("alta", []):
                # No t√≠tulo
                if ngram in titulo_lower:
                    pontuacoes_brutas[cat_id] += self.pesos["titulo_ngram_alta"]
                    expressoes_especificas += 1
                
                # No conte√∫do
                freq = conteudo_lower.count(ngram)
                if freq > 0:
                    pontuacoes_brutas[cat_id] += self.pesos["conteudo_ngram_alta"] * freq
                    expressoes_especificas += freq
            
            # M√©dia especificidade
            for ngram in ngrams.get("media", []):
                if ngram in titulo_lower:
                    pontuacoes_brutas[cat_id] += self.pesos["titulo_ngram_media"]
                
                freq = conteudo_lower.count(ngram)
                pontuacoes_brutas[cat_id] += self.pesos["conteudo_ngram_media"] * freq
            
            # B√¥nus diversidade
            if expressoes_especificas >= 3:
                pontuacoes_brutas[cat_id] += self.pesos["bonus_diversidade"]
        
        
        # ========== PATH B: TF-IDF (TOKENS) ==========
        for cat_id, tokens in self.tokens_simples.items():
            for token in tokens:
                # T√≠tulo
                if token in titulo_lower:
                    tfidf = self.calcular_tfidf_token(token, 1)
                    pontuacoes_brutas[cat_id] += self.pesos["titulo_token_tfidf"] * tfidf
                
                # Conte√∫do
                freq = conteudo_lower.count(token)
                if freq > 0:
                    tfidf = self.calcular_tfidf_token(token, freq)
                    pontuacoes_brutas[cat_id] += self.pesos["conteudo_token_tfidf"] * tfidf
        
        
        # ========== PATH C: LIVRO B√çBLICO (DESEMPATE) ==========
        livros_relacionados = {
            1: ["2 tim√≥teo", "salmos 119"],
            2: ["isa√≠as", "salmos", "j√≥"],
            3: ["g√™nesis 3", "romanos 3", "ef√©sios 2"],
            4: ["jo√£o", "mateus", "marcos", "lucas", "hebreus"],
            5: ["romanos", "ef√©sios", "jo√£o 3", "g√°latas"],
            6: ["atos", "jo√£o 14", "romanos 8"],
            7: ["ef√©sios 4", "1 cor√≠ntios", "atos 2"],
            8: ["apocalipse", "1 tessalonicenses", "2 pedro 3"]
        }
        
        if livro_principal:
            for cat_id, livros in livros_relacionados.items():
                for livro in livros:
                    if livro.lower() in livro_principal.lower():
                        pontuacoes_brutas[cat_id] += self.pesos["livro_biblico"]
        
        
        # ========== NORMALIZA√á√ÉO POR TAMANHO ==========
        pontuacoes_normalizadas = {
            cat_id: self.normalizar_por_tamanho(pont, tamanho_doc)
            for cat_id, pont in pontuacoes_brutas.items()
        }
        
        
        # ========== RANKING E SELE√á√ÉO ==========
        ranking = sorted(pontuacoes_normalizadas.items(), key=lambda x: x[1], reverse=True)
        
        tema_principal = ranking[0][0] if ranking and ranking[0][1] > 0 else None
        temas_secundarios = []
        
        if tema_principal and len(ranking) > 1:
            limiar = pontuacoes_normalizadas[tema_principal] * 0.30
            for cat_id, pontuacao in ranking[1:3]:
                if pontuacao >= limiar and pontuacao > 0:
                    temas_secundarios.append(cat_id)
        
        
        # ========== CALCULA PERCENTIL (CONFIAN√áA RELATIVA) ==========
        if tema_principal:
            self.pontuacoes_historico[tema_principal].append(pontuacoes_normalizadas[tema_principal])
        
        
        # ========== IDENTIFICA SUBTEMAS COM DENSIDADE ==========
        subtemas_densidade = self._identificar_subtemas_densidade(titulo, conteudo, tamanho_doc)
        
        
        # ========== MONTA CLASSIFICA√á√ÉO ==========
        classificacao = {
            "tema_principal": {
                "id": tema_principal,
                "nome": self.taxonomia_grudem[tema_principal]["nome"] if tema_principal else None,
                "pergunta_central": self.taxonomia_grudem[tema_principal]["pergunta_central"] if tema_principal else None,
                "confianca_normalizada": round(pontuacoes_normalizadas.get(tema_principal, 0), 2),
                "subtemas_detectados": subtemas_densidade.get(tema_principal, [])
            },
            "temas_secundarios": [
                {
                    "id": cat_id,
                    "nome": self.taxonomia_grudem[cat_id]["nome"],
                    "confianca_normalizada": round(pontuacoes_normalizadas[cat_id], 2),
                    "subtemas_detectados": subtemas_densidade.get(cat_id, [])
                }
                for cat_id in temas_secundarios
            ],
            "metodo": "H√≠brido (TF-IDF + Heur√≠stico) v3.1",
            "tamanho_documento": tamanho_doc
        }
        
        pregacao_classificada = {**pregacao}
        pregacao_classificada['classificacao_tematica'] = classificacao
        
        return pregacao_classificada
    
    
    def _identificar_subtemas_densidade(self, titulo: str, conteudo: str, tamanho: int) -> Dict[int, List[Dict]]:
        """
        Identifica subtemas com DENSIDADE (n√£o bin√°rio)
        
        MELHORIA v3.1:
        Subtemas agora t√™m intensidade (FORTE / MODERADA / MENCIONADA)
        
        Returns:
            {categoria_id: [{"nome": str, "intensidade": str, "freq": int}]}
        """
        subtemas_detectados = defaultdict(list)
        texto_completo = f"{titulo} {conteudo}".lower()
        
        mapa_subtemas = {
            1: {
                "autoridade": "Autoridade das Escrituras",
                "sufici√™ncia": "Sufici√™ncia da Palavra",
                "revela√ß√£o": "Revela√ß√£o de Deus"
            },
            2: {
                "santidade": "Santidade de Deus",
                "soberania": "Soberania de Deus",
                "trindade": "Trindade"
            },
            3: {
                "pecado": "Pecado",
                "queda": "Queda"
            },
            4: {
                "cruz": "Cruz",
                "ressurrei√ß√£o": "Ressurrei√ß√£o",
                "senhorio": "Senhorio de Cristo"
            },
            5: {
                "novo nascimento": "Novo nascimento",
                "justifica√ß√£o": "Justifica√ß√£o",
                "santifica√ß√£o": "Santifica√ß√£o"
            },
            6: {
                "regenera√ß√£o": "Regenera√ß√£o",
                "vida no esp√≠rito": "Vida no Esp√≠rito"
            },
            7: {
                "corpo de cristo": "Corpo de Cristo",
                "comunh√£o": "Comunh√£o"
            },
            8: {
                "esperan√ßa": "Esperan√ßa crist√£",
                "eternidade": "Eternidade",
                "segunda vinda": "Segunda vinda de Cristo"
            }
        }
        
        for cat_id, palavras_subtemas in mapa_subtemas.items():
            for palavra, subtema in palavras_subtemas.items():
                freq = texto_completo.count(palavra)
                
                if freq > 0:
                    # Calcula densidade (ocorr√™ncias por 1000 palavras)
                    densidade = (freq / max(tamanho, 1)) * 1000
                    
                    # Classifica intensidade
                    if densidade >= 2.0:
                        intensidade = "FORTE"
                    elif densidade >= 0.5:
                        intensidade = "MODERADA"
                    else:
                        intensidade = "MENCIONADA"
                    
                    subtemas_detectados[cat_id].append({
                        "nome": subtema,
                        "intensidade": intensidade,
                        "frequencia": freq,
                        "densidade": round(densidade, 2)
                    })
        
        return dict(subtemas_detectados)
    
    
    def classificar_lote(self, pregacoes: List[Dict]) -> List[Dict]:
        """Classifica lote"""
        self.treinar_idf(pregacoes)
        
        print(f"\nüè∑Ô∏è  Classificando {len(pregacoes)} prega√ß√µes (v3.1 H√≠brido)...")
        
        classificadas = []
        for i, pregacao in enumerate(pregacoes, 1):
            try:
                classificada = self.classificar_pregacao(pregacao)
                classificadas.append(classificada)
                
                if i % 50 == 0:
                    print(f"   ‚úì {i}/{len(pregacoes)}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erro: {e}")
                classificadas.append(pregacao)
        
        print(f"‚úÖ {len(classificadas)} classificadas")
        return classificadas
    
    
    def gerar_relatorio_tematico(self, pregacoes: List[Dict]) -> Dict:
        """Gera relat√≥rio"""
        print("\nüìä Gerando relat√≥rio...")
        
        temas_principais = Counter()
        temas_secundarios = Counter()
        temas_por_ano = defaultdict(Counter)
        subtemas_por_categoria = defaultdict(Counter)
        confianca_media = defaultdict(list)
        total_classificadas = 0
        
        for pregacao in pregacoes:
            classif = pregacao.get('classificacao_tematica')
            if not classif:
                continue
            
            total_classificadas += 1
            tema_princ = classif.get('tema_principal', {})
            
            if tema_princ.get('id'):
                nome = tema_princ['nome']
                temas_principais[nome] += 1
                confianca_media[nome].append(tema_princ.get('confianca_normalizada', 0))
                
                for subtema_dict in tema_princ.get('subtemas_detectados', []):
                    if isinstance(subtema_dict, dict):
                        subtemas_por_categoria[nome][subtema_dict['nome']] += 1
                    else:
                        subtemas_por_categoria[nome][subtema_dict] += 1
                
                ano = pregacao.get('ano')
                if ano:
                    temas_por_ano[ano][nome] += 1
            
            for tema_sec in classif.get('temas_secundarios', []):
                temas_secundarios[tema_sec['nome']] += 1
        
        conf_media = {
            tema: sum(valores) / len(valores) if valores else 0
            for tema, valores in confianca_media.items()
        }
        
        return {
            "resumo": {
                "total_pregacoes": len(pregacoes),
                "classificadas": total_classificadas,
                "metodo": "H√≠brido (TF-IDF + Heur√≠stico) v3.1"
            },
            "temas_principais": dict(temas_principais.most_common()),
            "temas_secundarios": dict(temas_secundarios.most_common()),
            "confianca_media": {tema: round(c, 2) for tema, c in conf_media.items()},
            "subtemas": {
                tema: dict(subs.most_common(5))
                for tema, subs in subtemas_por_categoria.items()
            },
            "distribuicao_anual": {
                ano: dict(temas) for ano, temas in sorted(temas_por_ano.items())
            },
            "top_5": temas_principais.most_common(5)
        }
    
    
    def imprimir_relatorio(self, relatorio: Dict):
        """Imprime relat√≥rio"""
        print("\n" + "=" * 80)
        print("üè∑Ô∏è  RELAT√ìRIO v3.1 - MODELO H√çBRIDO")
        print("=" * 80)
        
        resumo = relatorio['resumo']
        print(f"\nüî∑ RESUMO:")
        print(f"   Total: {resumo['total_pregacoes']}")
        print(f"   M√©todo: {resumo['metodo']}")
        
        print(f"\nüî∑ TOP 5 TEMAS:")
        for i, (tema, qtd) in enumerate(relatorio['top_5'], 1):
            perc = (qtd / resumo['classificadas']) * 100
            conf = relatorio['confianca_media'].get(tema, 0)
            print(f"   {i}. {tema:45} - {qtd:3d}x ({perc:.1f}%) | conf: {conf:.1f}")
        
        print("\n" + "=" * 80)
    
    
    def salvar_classificadas(self, pregacoes: List[Dict], caminho: str = "../../output/pregacoes_classificadas_v31.json"):
        """Salva classificadas"""
        caminho_path = Path(caminho)
        caminho_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(caminho_path, 'w', encoding='utf-8') as f:
            json.dump({
                "descricao": "Classifica√ß√£o H√≠brida v3.1 (TF-IDF + Heur√≠stico)",
                "metodologia": "Sistema h√≠brido: TF-IDF para tokens + Scoring especialista para n-grams",
                "total": len(pregacoes),
                "pregacoes": pregacoes
            }, f, ensure_ascii=False, indent=2)
        
        tamanho_mb = caminho_path.stat().st_size / (1024 * 1024)
        print(f"üíæ Salvo: {caminho_path.resolve()} ({tamanho_mb:.1f} MB)")


# ==================== TESTE ====================

if __name__ == "__main__":
    import json
    from pathlib import Path
    
    print("\n" + "=" * 80)
    print("üß™ TESTE v3.1 - MODELO H√çBRIDO RIGOROSO")
    print("=" * 80)
    
    arquivo = Path("../../output/pregacoes_enriquecidas_completo.json")
    
    if arquivo.exists():
        with open(arquivo, 'r', encoding='utf-8') as f:
            dados = json.load(f)
        
        pregacoes = dados.get('pregacoes', [])
        print(f"\nüìö {len(pregacoes)} prega√ß√µes carregadas")
        
        classifier = ThematicClassifier()
        classificadas = classifier.classificar_lote(pregacoes)
        
        # Exemplo
        print("\n" + "=" * 80)
        print("üìñ EXEMPLO COM SUBTEMAS DENSIDADE:")
        exemplo = classificadas[0]
        print(f"\nüìå {exemplo['titulo']}")
        
        tema = exemplo['classificacao_tematica']['tema_principal']
        print(f"\nüéØ {tema['nome']}")
        print(f"   Confian√ßa: {tema['confianca_normalizada']:.2f}")
        
        if tema.get('subtemas_detectados'):
            print(f"\n   üìé Subtemas (com densidade):")
            for sub in tema['subtemas_detectados']:
                if isinstance(sub, dict):
                    print(f"      ‚Ä¢ {sub['nome']:30} [{sub['intensidade']:10}] ({sub['frequencia']}x, densidade: {sub['densidade']})")
        
        # Relat√≥rio
        relatorio = classifier.gerar_relatorio_tematico(classificadas)
        classifier.imprimir_relatorio(relatorio)
        
        # Salva
        classifier.salvar_classificadas(classificadas)
        
        with open("../../output/relatorio_v31.json", 'w', encoding='utf-8') as f:
            json.dump(relatorio, f, ensure_ascii=False, indent=2)
        print("üíæ Relat√≥rio v3.1 salvo")
    
    else:
        print(f"‚ùå {arquivo} n√£o encontrado")
